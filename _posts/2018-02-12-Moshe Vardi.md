---
layout:     post
title:      Moshe Vardi
subtitle:   Don't be selfish. Peace. 
date:       2018-02-12 12:06:00
author:     "Rohit Naidu"
header-img: "img/moshe-vardi.jpg"
categories: Safety
---

# Interview with Dr. Moshe Vardi

Professor of Computer Science at Rice University, Gödel Prize Winner 

## Question 1: What inspired you to dive into Computer Science? (Rohit Naidu)
Reply: “So when I was 16 years old which was a long time ago, I saw an advertisement in the paper, about a two week course for programming. Computer programming. And at that time I knew absolutely nothing and I had no idea what was a computer. But I was somehow fascinated by the idea and I took an intensive two week course in FORTRAN programming. It’s one of the very first programming languages going back to the 1950s, and today most people think of it as an ancient language, but at the time it was a cutting edge language and I fell in love with programming, I thought programming was so much fun. So the rest is history.”

## Question 2: If we can create a complex program like AI, why don’t we have control over it?
Reply: “If you think about it, this is part of a technology challenge, it always has been on two sides. On one hand we want technology that does more, more and more. This is in every area in technology. You know, we are trying to build increased capability. And whenever we increase capability, invariably we increase the complexity of the system. Think of a Boeing – 787, the complexity of the system. And as we increase the complexity of the system, it becomes more and more difficult to understand what the system is doing and to have full control over what the system is doing. So, this has been one of the challenges, going back to the beginning of technology, if you think about it, the very beginning of technology may be the discovery of fire. The human being discovered that they can use fire to roast the meat from the mammoth and cooked meat was easier to chew than uncooked meat. What happens when you have fire? Well, sometimes you lose control over the fire. So even today, who knows hundreds and thousands of years we have tamed the fire and still we have the love hate relationship with the fire. You think it is going to be very difficult for us to live most of our lives without fire but every year see how many people die, are injured and damaged by fire. We always have this complex relationship with technology and which is we want to be the master of technology, but we are not fully successful. Think about it, the automobile again has been an amazing technology in terms of mobility and every year more than a million people are killed by car crashes. And so, we are facing the same dilemma with AI. We are trying to build programs, again, AI are just programs, but we want it to do more and more. So the program is getting more and more complex. As the program becomes more and more complex, it is harder and harder for us to understand exactly how it behaves. One of the thing that we do know about Turing Machines, it is such a simple motor. Just you simply have a ‘head’, the head goes to the left and the right and write the symbol, very, very simple and some instructions. Nevertheless, we know that if you give me a Turing machine and ask me, will it stop if it starts from an empty tape? Will it terminate? This is what we call undecidable. There is no way to predict in advance, how it will behave. The only way to know how it will behave is to try and see what happens. So we know today, it is very easy with a very simple number of components to build very complex systems and it’s very, very hard to predict their behavior. And so this is the challenge for us is always on one hand we are trying to build more and more complex systems in the area of AI, but at the same time how do we ensure that we still keep control over the system? And in particular with AI there is now the fear that we would lose control over technology and this is an old fear. This fear goes back to 19th century Frankenstein which had to do again, how do we keep control of our technology and we make sure that we are the master of technology? And now there is a debate. How do we ensure it? There is one phrase that you hear now about “EXPLAINABLE AI”. We want to make sure that when the AI is making a decision, we can explain it in a way that we can say, yes I understand the decision. Not just a black box. And so when AI systems start talking in al language we fear that we are going to lose control, we don’t know what it does, how does it behave. And this is going to be a continuing dilemma for us. As technology gets more and more powerful, how do we ensure that we are in control? Have you seen the movie Space Odyssey 2001? Remember HAL the computer? HAL: “I’m afraid I cannot do that Dave”. Again this is an example. So this is an old fear, and this gave rise to a serious research question. How do we ensure that this does not happen? And the answer is really the same way we cannot fully predict the behavior of Turing machines, we can never fully predict the behavior of any technology. We always live on the cutting edge some people say on the bleeding edge of technology, that as were rushing to advanced technology, very often it gets away from us and it shows us we have to be humble. It teaches us humility. We think we are the master, well… not quite. Technology sometimes it seems to have its own mind.”
